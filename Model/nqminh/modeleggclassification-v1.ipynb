{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7490549,"sourceType":"datasetVersion","datasetId":4361124}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms, datasets\nfrom torch.utils.data import DataLoader, random_split\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T16:07:24.748147Z","iopub.execute_input":"2025-10-29T16:07:24.748416Z","iopub.status.idle":"2025-10-29T16:07:32.270581Z","shell.execute_reply.started":"2025-10-29T16:07:24.748350Z","shell.execute_reply":"2025-10-29T16:07:32.269935Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os \nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom collections import Counter","metadata":{"trusted":true,"execution":{"iopub.status.idle":"2025-10-29T16:07:33.616112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/eggs-images-classification-damaged-or-not/Eggs Classification'\n\nclasses = os.listdir(dataset_dir)\nprint(f\"classes: {classes}\")\n\nfor cls in classes:\n    cls_path = os.path.join(dataset_dir, cls)\n    print(f\"{cls}: {len(os.listdir(cls_path))} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T16:07:33.616881Z","iopub.execute_input":"2025-10-29T16:07:33.617083Z","iopub.status.idle":"2025-10-29T16:07:33.684928Z","shell.execute_reply.started":"2025-10-29T16:07:33.617068Z","shell.execute_reply":"2025-10-29T16:07:33.684326Z"}},"outputs":[{"name":"stdout","text":"classes: ['Damaged', 'Not Damaged']\nDamaged: 632 images\nNot Damaged: 162 images\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(), # Change shape (C, H, W)\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                        std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T16:09:17.397996Z","iopub.execute_input":"2025-10-29T16:09:17.398261Z","iopub.status.idle":"2025-10-29T16:09:17.403511Z","shell.execute_reply.started":"2025-10-29T16:09:17.398243Z","shell.execute_reply":"2025-10-29T16:09:17.402835Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Load full dataset\nfull_dataset = datasets.ImageFolder(root='/kaggle/input/eggs-images-classification-damaged-or-not/Eggs Classification', transform=train_transform)\n\n# Split data \ntrain_ratio = 0.8\nval_ratio = 0.2\ntotal_size = len(full_dataset)\ntrain_size = int(total_size * train_ratio)\nval_size = total_size -  train_size\n\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\nval_dataset.dataset.transform = val_transform # Override train_transform\n\n# Create dataloader\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T16:09:20.795481Z","iopub.execute_input":"2025-10-29T16:09:20.795747Z","iopub.status.idle":"2025-10-29T16:09:21.155747Z","shell.execute_reply.started":"2025-10-29T16:09:20.795727Z","shell.execute_reply":"2025-10-29T16:09:21.155165Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Load model (a prestrain model)\nmodel = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 2) # for normal and break\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T16:09:25.740446Z","iopub.execute_input":"2025-10-29T16:09:25.741107Z","iopub.status.idle":"2025-10-29T16:09:25.962184Z","shell.execute_reply.started":"2025-10-29T16:09:25.741083Z","shell.execute_reply":"2025-10-29T16:09:25.961547Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"num_epochs = 20\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels =  images.to(device), labels.to(device)\n        optimizer.zero_grad() # Clear the previous gradient\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward() # Compute gradient (backpropagation)\n        optimizer.step() # update parameter (w - n*gradient)\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1) # take the label have the highest value, ignore the valuye \n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    train_acc = 100 * correct / total\n    print(f\"Epoch [{epoch+1}/{num_epochs}] \" \n          f\"Loss: {running_loss/len(train_loader):.4f} \" \n          f\"Train Acc: {train_acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T16:09:29.332570Z","iopub.execute_input":"2025-10-29T16:09:29.333107Z","iopub.status.idle":"2025-10-29T16:14:49.500657Z","shell.execute_reply.started":"2025-10-29T16:09:29.333086Z","shell.execute_reply":"2025-10-29T16:14:49.499957Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/20] Loss: 0.4309 Train Acc: 78.43%\nEpoch [2/20] Loss: 0.0470 Train Acc: 99.37%\nEpoch [3/20] Loss: 0.0308 Train Acc: 99.21%\nEpoch [4/20] Loss: 0.0115 Train Acc: 99.84%\nEpoch [5/20] Loss: 0.0087 Train Acc: 99.69%\nEpoch [6/20] Loss: 0.0111 Train Acc: 99.69%\nEpoch [7/20] Loss: 0.0050 Train Acc: 99.69%\nEpoch [8/20] Loss: 0.0066 Train Acc: 99.84%\nEpoch [9/20] Loss: 0.0080 Train Acc: 99.69%\nEpoch [10/20] Loss: 0.0038 Train Acc: 99.84%\nEpoch [11/20] Loss: 0.0039 Train Acc: 99.84%\nEpoch [12/20] Loss: 0.0056 Train Acc: 99.69%\nEpoch [13/20] Loss: 0.0084 Train Acc: 99.53%\nEpoch [14/20] Loss: 0.0601 Train Acc: 97.80%\nEpoch [15/20] Loss: 0.0435 Train Acc: 99.06%\nEpoch [16/20] Loss: 0.0235 Train Acc: 99.21%\nEpoch [17/20] Loss: 0.0110 Train Acc: 99.53%\nEpoch [18/20] Loss: 0.0063 Train Acc: 99.69%\nEpoch [19/20] Loss: 0.0050 Train Acc: 99.84%\nEpoch [20/20] Loss: 0.0037 Train Acc: 99.84%\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\nval_acc = 100 * correct / total\nprint(f\"Validation Accuracy: {val_acc:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T16:18:05.678731Z","iopub.execute_input":"2025-10-29T16:18:05.679515Z","iopub.status.idle":"2025-10-29T16:18:09.979409Z","shell.execute_reply.started":"2025-10-29T16:18:05.679491Z","shell.execute_reply":"2025-10-29T16:18:09.978618Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 98.74%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}